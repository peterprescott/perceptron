{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP527 Data Mining & Visualization: Text Classification Using Binary Perceptron Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Student 201442927. University of Liverpool.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions/Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) Explain the Perceptron algorithm for the binary classification case, providing its pseudo code. (20 marks)\n",
    "\n",
    "(2) Prove that for a linearly separable dataset, perceptron algorithm will converge. (10 marks)\n",
    "\n",
    "(3) Implement a binary perceptron. (20 marks)\n",
    "\n",
    "(4) Use the binary perceptron to train classifiers to discriminate between (a) class 1 and class 2,\n",
    "(b) class 2 and class 3 and (c) class 1 and class 3. Report the train and test classification\n",
    "accuracies for each of the three classifiers after 20 iterations. Which pair of classes is most\n",
    "difficult to separate? (20 marks)\n",
    "\n",
    "(5) For the classifier (a) implemented in part (3) above, which feature is the most discriminative? (5 marks)\n",
    "\n",
    "(6) Extend the binary perceptron that you implemented in part (2) above to perform multi-class\n",
    "classification using the 1-vs-rest approach. Report the train and test classification accuracies\n",
    "for each of the three classes after training for 20 iterations. (15 marks),\n",
    "\n",
    "(7) Add an $ \\ell_{2} $ regularisation term to your multi-class classifier implemented in question (5). Set\n",
    "the regularisation coefficient to 0.01, 0.1, 1.0, 10.0, 100.0 and compare the train and test\n",
    "classification accuracy for each of the three classes. (10 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task (1) \n",
    ">Explain the Perceptron algorithm for the binary classification case, providing its pseudo code. (20 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *Perceptron Algorithm*, first described by Frank Rosenblatt in 1958, is inspired by the idea of a biological neuron which is sensitive to a number of stimuli and is deterministically activated when the effect of those combined stimuli exceeds some activation threshold.\n",
    "\n",
    "Mathematically, we model this as the dot product of a vector of quantified stimuli $\\mathbf{x}_{i}$ and a vector of weighted sensitivities $\\mathbf{w}_{i}$, plus a bias term $ b $.\n",
    "\n",
    "Given a dataset that can be described as a linearly-separable collection of vectors, and has already been divided into two disjoint labelled categories, we \n",
    "\n",
    "\n",
    "the Perceptron Algorithm shows how to adjust our model's sensitivity weights and bias until the model is able to correctly classify all of our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In pseudo-code:\n",
    "\n",
    "// initialize weights\n",
    "// initialize bias\n",
    "\n",
    "\n",
    "\n",
    "The Algorithm provides a recipe for \n",
    "\n",
    "In pseudo-code\n",
    "Input: ProblemSize, InputPatterns, , \n",
    "Output: Weights\n",
    "Weights  InitializeWeights(ProblemSize)\n",
    "For ( To )\n",
    "      SelectInputPattern(InputPatterns)\n",
    "      ActivateNetwork(, Weights)\n",
    "      TransferActivation()\n",
    "    UpdateWeights(, , )\n",
    "End\n",
    "Return (Weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task (2) \n",
    "> Prove that for a linearly separable dataset, perceptron algorithm will converge. (10 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task (3) \n",
    "> Implement a binary perceptron. (20 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename, with_print=False):\n",
    "    \"\"\"\n",
    "    Read in labelled data from file.\n",
    "    \n",
    "    Args:\n",
    "        filename (str): Name of file in local directory.\n",
    "    \"\"\"\n",
    "    \n",
    "    # open the file\n",
    "    with open(filename,'r') as f:\n",
    "        file_data = f.read()\n",
    "\n",
    "    # split lines\n",
    "    split_data = file_data.split('\\n')\n",
    "\n",
    "    # creat dict to store data\n",
    "    data = {}\n",
    "    for i, datum in enumerate(split_data):\n",
    "        try:\n",
    "            # split the data-vector from the class-label\n",
    "            split = datum.split(',class-')\n",
    "            label = split[1]\n",
    "            \n",
    "            # split the elements of the data-vector\n",
    "            list_of_strings = split[0].split(',')\n",
    "            list_vector = []\n",
    "            \n",
    "            # convert the elements of the data-vector...\n",
    "            # ... from text strings to floating-point numbers\n",
    "            for string in list_of_strings:\n",
    "                element = float(string)\n",
    "                list_vector.append(element)\n",
    "            \n",
    "            # convert the list of floats to a numpy array vector\n",
    "            vector = np.array(list_vector)\n",
    "            \n",
    "            # load the label and vector into the data dict\n",
    "            data[i] = (label, vector)\n",
    "            \n",
    "            if with_print==True:\n",
    "                print(f'Extracted \"{datum}\" to \"{data[i]}\".')\n",
    "        except IndexError:\n",
    "            if with_print==True:\n",
    "                print(f'Could not split \"{datum}\".\\nProbably this was the end of the file.')\n",
    "            \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = load_data('test.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_data('train.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ('1', array([5.1, 3.5, 1.4, 0.2])),\n",
       " 1: ('1', array([4.9, 3. , 1.4, 0.2])),\n",
       " 2: ('1', array([4.7, 3.2, 1.3, 0.2])),\n",
       " 3: ('1', array([4.6, 3.1, 1.5, 0.2])),\n",
       " 4: ('1', array([5. , 3.6, 1.4, 0.2])),\n",
       " 5: ('1', array([5.4, 3.9, 1.7, 0.4])),\n",
       " 6: ('1', array([4.6, 3.4, 1.4, 0.3])),\n",
       " 7: ('1', array([5. , 3.4, 1.5, 0.2])),\n",
       " 8: ('1', array([4.4, 2.9, 1.4, 0.2])),\n",
       " 9: ('1', array([4.9, 3.1, 1.5, 0.1])),\n",
       " 10: ('1', array([5.4, 3.7, 1.5, 0.2])),\n",
       " 11: ('1', array([4.8, 3.4, 1.6, 0.2])),\n",
       " 12: ('1', array([4.8, 3. , 1.4, 0.1])),\n",
       " 13: ('1', array([4.3, 3. , 1.1, 0.1])),\n",
       " 14: ('1', array([5.8, 4. , 1.2, 0.2])),\n",
       " 15: ('1', array([5.7, 4.4, 1.5, 0.4])),\n",
       " 16: ('1', array([5.4, 3.9, 1.3, 0.4])),\n",
       " 17: ('1', array([5.1, 3.5, 1.4, 0.3])),\n",
       " 18: ('1', array([5.7, 3.8, 1.7, 0.3])),\n",
       " 19: ('1', array([5.1, 3.8, 1.5, 0.3])),\n",
       " 20: ('1', array([5.4, 3.4, 1.7, 0.2])),\n",
       " 21: ('1', array([5.1, 3.7, 1.5, 0.4])),\n",
       " 22: ('1', array([4.6, 3.6, 1. , 0.2])),\n",
       " 23: ('1', array([5.1, 3.3, 1.7, 0.5])),\n",
       " 24: ('1', array([4.8, 3.4, 1.9, 0.2])),\n",
       " 25: ('1', array([5. , 3. , 1.6, 0.2])),\n",
       " 26: ('1', array([5. , 3.4, 1.6, 0.4])),\n",
       " 27: ('1', array([5.2, 3.5, 1.5, 0.2])),\n",
       " 28: ('1', array([5.2, 3.4, 1.4, 0.2])),\n",
       " 29: ('1', array([4.7, 3.2, 1.6, 0.2])),\n",
       " 30: ('1', array([4.8, 3.1, 1.6, 0.2])),\n",
       " 31: ('1', array([5.4, 3.4, 1.5, 0.4])),\n",
       " 32: ('1', array([5.2, 4.1, 1.5, 0.1])),\n",
       " 33: ('1', array([5.5, 4.2, 1.4, 0.2])),\n",
       " 34: ('1', array([4.9, 3.1, 1.5, 0.1])),\n",
       " 35: ('1', array([5. , 3.2, 1.2, 0.2])),\n",
       " 36: ('1', array([5.5, 3.5, 1.3, 0.2])),\n",
       " 37: ('1', array([4.9, 3.1, 1.5, 0.1])),\n",
       " 38: ('1', array([4.4, 3. , 1.3, 0.2])),\n",
       " 39: ('1', array([5.1, 3.4, 1.5, 0.2])),\n",
       " 40: ('2', array([7. , 3.2, 4.7, 1.4])),\n",
       " 41: ('2', array([6.4, 3.2, 4.5, 1.5])),\n",
       " 42: ('2', array([6.9, 3.1, 4.9, 1.5])),\n",
       " 43: ('2', array([5.5, 2.3, 4. , 1.3])),\n",
       " 44: ('2', array([6.5, 2.8, 4.6, 1.5])),\n",
       " 45: ('2', array([5.7, 2.8, 4.5, 1.3])),\n",
       " 46: ('2', array([6.3, 3.3, 4.7, 1.6])),\n",
       " 47: ('2', array([4.9, 2.4, 3.3, 1. ])),\n",
       " 48: ('2', array([6.6, 2.9, 4.6, 1.3])),\n",
       " 49: ('2', array([5.2, 2.7, 3.9, 1.4])),\n",
       " 50: ('2', array([5. , 2. , 3.5, 1. ])),\n",
       " 51: ('2', array([5.9, 3. , 4.2, 1.5])),\n",
       " 52: ('2', array([6. , 2.2, 4. , 1. ])),\n",
       " 53: ('2', array([6.1, 2.9, 4.7, 1.4])),\n",
       " 54: ('2', array([5.6, 2.9, 3.6, 1.3])),\n",
       " 55: ('2', array([6.7, 3.1, 4.4, 1.4])),\n",
       " 56: ('2', array([5.6, 3. , 4.5, 1.5])),\n",
       " 57: ('2', array([5.8, 2.7, 4.1, 1. ])),\n",
       " 58: ('2', array([6.2, 2.2, 4.5, 1.5])),\n",
       " 59: ('2', array([5.6, 2.5, 3.9, 1.1])),\n",
       " 60: ('2', array([5.9, 3.2, 4.8, 1.8])),\n",
       " 61: ('2', array([6.1, 2.8, 4. , 1.3])),\n",
       " 62: ('2', array([6.3, 2.5, 4.9, 1.5])),\n",
       " 63: ('2', array([6.1, 2.8, 4.7, 1.2])),\n",
       " 64: ('2', array([6.4, 2.9, 4.3, 1.3])),\n",
       " 65: ('2', array([6.6, 3. , 4.4, 1.4])),\n",
       " 66: ('2', array([6.8, 2.8, 4.8, 1.4])),\n",
       " 67: ('2', array([6.7, 3. , 5. , 1.7])),\n",
       " 68: ('2', array([6. , 2.9, 4.5, 1.5])),\n",
       " 69: ('2', array([5.7, 2.6, 3.5, 1. ])),\n",
       " 70: ('2', array([5.5, 2.4, 3.8, 1.1])),\n",
       " 71: ('2', array([5.5, 2.4, 3.7, 1. ])),\n",
       " 72: ('2', array([5.8, 2.7, 3.9, 1.2])),\n",
       " 73: ('2', array([6. , 2.7, 5.1, 1.6])),\n",
       " 74: ('2', array([5.4, 3. , 4.5, 1.5])),\n",
       " 75: ('2', array([6. , 3.4, 4.5, 1.6])),\n",
       " 76: ('2', array([6.7, 3.1, 4.7, 1.5])),\n",
       " 77: ('2', array([6.3, 2.3, 4.4, 1.3])),\n",
       " 78: ('2', array([5.6, 3. , 4.1, 1.3])),\n",
       " 79: ('2', array([5.5, 2.5, 4. , 1.3])),\n",
       " 80: ('3', array([6.3, 3.3, 6. , 2.5])),\n",
       " 81: ('3', array([5.8, 2.7, 5.1, 1.9])),\n",
       " 82: ('3', array([7.1, 3. , 5.9, 2.1])),\n",
       " 83: ('3', array([6.3, 2.9, 5.6, 1.8])),\n",
       " 84: ('3', array([6.5, 3. , 5.8, 2.2])),\n",
       " 85: ('3', array([7.6, 3. , 6.6, 2.1])),\n",
       " 86: ('3', array([4.9, 2.5, 4.5, 1.7])),\n",
       " 87: ('3', array([7.3, 2.9, 6.3, 1.8])),\n",
       " 88: ('3', array([6.7, 2.5, 5.8, 1.8])),\n",
       " 89: ('3', array([7.2, 3.6, 6.1, 2.5])),\n",
       " 90: ('3', array([6.5, 3.2, 5.1, 2. ])),\n",
       " 91: ('3', array([6.4, 2.7, 5.3, 1.9])),\n",
       " 92: ('3', array([6.8, 3. , 5.5, 2.1])),\n",
       " 93: ('3', array([5.7, 2.5, 5. , 2. ])),\n",
       " 94: ('3', array([5.8, 2.8, 5.1, 2.4])),\n",
       " 95: ('3', array([6.4, 3.2, 5.3, 2.3])),\n",
       " 96: ('3', array([6.5, 3. , 5.5, 1.8])),\n",
       " 97: ('3', array([7.7, 3.8, 6.7, 2.2])),\n",
       " 98: ('3', array([7.7, 2.6, 6.9, 2.3])),\n",
       " 99: ('3', array([6. , 2.2, 5. , 1.5])),\n",
       " 100: ('3', array([6.9, 3.2, 5.7, 2.3])),\n",
       " 101: ('3', array([5.6, 2.8, 4.9, 2. ])),\n",
       " 102: ('3', array([7.7, 2.8, 6.7, 2. ])),\n",
       " 103: ('3', array([6.3, 2.7, 4.9, 1.8])),\n",
       " 104: ('3', array([6.7, 3.3, 5.7, 2.1])),\n",
       " 105: ('3', array([7.2, 3.2, 6. , 1.8])),\n",
       " 106: ('3', array([6.2, 2.8, 4.8, 1.8])),\n",
       " 107: ('3', array([6.1, 3. , 4.9, 1.8])),\n",
       " 108: ('3', array([6.4, 2.8, 5.6, 2.1])),\n",
       " 109: ('3', array([7.2, 3. , 5.8, 1.6])),\n",
       " 110: ('3', array([7.4, 2.8, 6.1, 1.9])),\n",
       " 111: ('3', array([7.9, 3.8, 6.4, 2. ])),\n",
       " 112: ('3', array([6.4, 2.8, 5.6, 2.2])),\n",
       " 113: ('3', array([6.3, 2.8, 5.1, 1.5])),\n",
       " 114: ('3', array([6.1, 2.6, 5.6, 1.4])),\n",
       " 115: ('3', array([7.7, 3. , 6.1, 2.3])),\n",
       " 116: ('3', array([6.3, 3.4, 5.6, 2.4])),\n",
       " 117: ('3', array([6.4, 3.1, 5.5, 1.8])),\n",
       " 118: ('3', array([6. , 3. , 4.8, 1.8])),\n",
       " 119: ('3', array([6.9, 3.1, 5.4, 2.1]))}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_perceptron(training_dataset):\n",
    "    \"\"\"Train Perceptron on given training dataset.\n",
    "    \n",
    "    Args:\n",
    "        training_dataset(dict): Dict with integer keys containing tuples \n",
    "                            with labels and np.array data vectors.\"\"\"\n",
    "    \n",
    "    # load training_dataset\n",
    "    data = training_dataset\n",
    "    \n",
    "    # find length of dataset vectors\n",
    "    vector_length = len(data[0][1])\n",
    "    \n",
    "    # initialize weight_vector\n",
    "    weight_vector = np.zeros(vector_length + 1)\n",
    "    \n",
    "    return vector_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_perceptron(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0.])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.33"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task (4) \n",
    "> Use the binary perceptron to train classifiers to discriminate between (a) class 1 and class 2, (b) class 2 and class 3 and (c) class 1 and class 3. Report the train and test classification accuracies for each of the three classifiers after 20 iterations. Which pair of classes is most difficult to separate? (20 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task (5) \n",
    "> For the classifier (a) implemented in part (3) above, which feature is the most discriminative? (5 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task (6) \n",
    "> Extend the binary perceptron that you implemented in part (2) above to perform multi-class classification using the 1-vs-rest approach. Report the train and test classification accuracies for each of the three classes after training for 20 iterations. (15 marks),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task (7) \n",
    "> Add an $\\ell_{2}$ regularisation term to your multi-class classifier implemented in question (5). Set the regularisation coefficient to 0.01, 0.1, 1.0, 10.0, 100.0 and compare the train and test classification accuracy for each of the three classes. (10 marks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
